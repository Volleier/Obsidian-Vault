# 介绍

“拟合”（fitting）指在观测数据上构建参数化数学模型，使模型能够近似描述数据的生成规律。计算机视觉中常见的拟合问题包括直线/平面拟合、基础矩阵/本质矩阵估计、单应性/透视变换求解、以及三维点云的平面拟合等。

鲁棒估计（robust estimation）关注在含有异常值（outliers）或噪声的观测下，如何得到稳定可靠的模型参数。传统最小二乘法在面对异常值时会被强烈破坏，因而需要发展鲁棒方法（如 M-estimators、RANSAC）来抑制或剔除# 数学基础

异常数据

---

## 1. 最小二乘法（Least Square 给定观测对 (${(x*i,y_i)}*{i=1}^N$) 或更一般的设计矩阵 \(A\) 与观测向量 \(b\)，线性最小二乘问题为：

\) 与观测向量 \(b\)，线性最小二乘问题为：

$$
\min_{\mathbf{p}} \|A\mathbf{p} - b\|_2^2.
$$

正规解（若 \(A^TA\) 可逆）：

$$
\mathbf{p}^*=(A^TA)^{-1}A^Tb.
$$

### 1.2 几何理解

最小二乘求解是把观测向量 \(b\) 投影到由列空间 \(\mathcal{C}(A)\) 张成的子空间上，解对应于使残差向量 \(r=b-A\mathbf{p}\) 与 \(\mathcal{C}(A)\) 正交（正规方程 \(A^T r=0\)）。

### 1.3 局限性

- **对异常值极为敏感**：平方误差会放大离群点的影响。
- **模型假设**：线性最小二乘假定观测噪声为 i.i.d. 高斯，若噪声分布偏离，高斯假设不成立时效果下降。
- **几何/代价不一致**：在某些计算机视觉问题中（例如透视变换的像点对），直接对像素## 总体最小二乘 / 总体最小二乘法（Total Least Squares, TLS）与几何视角
  . 总体最小二乘 / 总体最小二乘法（Total Least Squares, TLS）与几何视角

### 2.1 问题动机

普通最小二乘仅考虑观测变量 \(b\) 含噪，而假定设计矩阵 \(A\) 精确。但在许多视觉问题中，\(A\) 亦由测量得到并含噪（如直接使用像点坐标构建的矩阵）。TLS 允许对 \(A\) 和 \(b\) 同时建模噪声。

### 2.2 TLS 表述

寻找最小扰动 \(\Delta A, \Delta b\) 使得 \((A+\Delta A)\mathbf{p}=b+\Delta b\) 且扰动 Frobenius 范数最小：

$$
\min_{\Delta A,\Delta b,\mathbf{p}} \|[\Delta A\ \Delta b]\|_F \quad\text{s.t. } (A+\Delta A)\mathbf{p}=b+\Delta b.
$$

通过把 \([A\ b]\) 做奇异值分解（SVD），TLS 解可从最小奇异值对应的奇异向量导出。

### 2.3 几何视角

TLS 实际上是在寻找一个低秩近似，使得带参数的超平面能穿过扰动后的观测点集合；几何上等价于对观测点做最小正交距离拟合（而非沿某一坐标轴的投影误差）。

### 2.4 局限性与数值注意

- TLS 对离群点仍不鲁棒（会被异常值影响）。
- SVD 计算开销相对高；对大规模问题需考虑分块或迭代方法。

---

## 3. 鲁棒估计的基本思想

鲁棒估计通过修改损失函数或采样策略来降低异常值的影响。常见思想包括：

- **替换代价函数（M-estimators）**：把平方误差替换为对异常值增长更慢的损失（Huber、Cauchy、Tukey 等），对应加权最小二乘的迭代重加权最小二乘（IRLS）实现。优势是平滑且统计效率高；缺点需选择尺度参数且对大比例外点并非总能收敛到正确解。

- \*\*样本分离# 实现

# 实现
## RANSAC：随机采样一致性（Random Sample Consensus）

### 4.1 核心思想

RANSAC 的基本想法是：在含有大量异常值的样本中，随机### 算法流程（伪 1. 给定模型类型（及最小样本数 s）、内点阈值 ($\tau$)、最大迭代次数或置信度要求。

择内点数最多或代价最低的模型，并以其内点重新估计最终模型。

### 4.2 算法流程 b. 计算所有样本到模型的误差（几何距离或重投影误差），判定哪些为内点（误差 < ($\tau$)）。

2. 重复直到达到迭代次数或置信度：  
   a. 随机从数据中抽取 s 个样本，估计模型参数。  
   b. 计算所有样本到模型的误差（几何距离或重投影误差），判定哪些为内### 关键参数与设定策略

   c. 若当前内点数超过历史最好，则保存该模型并（可选）用内点重估模型参数。

3. 输出包含最多内点的模型并用其内点做最终精修（例如用最小二乘在内点上迭代求解）。

### 4.3 关键参数与设定策略

- **最小样本数 s**：由模型自由度决定（例如单应性 4 对点 → s=4；基础矩阵估计 7 或 8 点法 → s=7/8）。
- **内点阈值 \(\tau\)**：与观测噪声、图像尺度、误差度量有关；通常需通过经验或按噪声估计设定。阈值过小会漏掉真实内点，过大则容易把外点包含进内点集合。
- **迭代次数 / 置信度**：给定内点比率估计 \(w\)（如果未知可保守设定），为获得至少一次选到纯内点样本的概率为 \(p\)，需的迭代次数 \(N\) 满足：

- **模型得分函数**：除内点计数外，可用加权内点得分（例如以残差反函数加权）以区分内点质量。

### 4.4 RANSAC 的改进与变体

- \*\*LO-RANSAC / Local Op### 优缺点总结
- 优点：极强的抗外点能力；实现简单且在视觉任务中非常有效。
- 缺点：随机性导致结果不确定；在低内点率时需要大量迭代；阈值与参数调优依赖经验；对模型复杂度敏感（高自由度模型难以在有限样本下抽到纯内点. (1981). Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography.
- Huber, P. J. (1981). Robust Statistics.


## 霍夫变换

霍夫变换是一类把图像空间的局部点集合映射到参数空间并通过累加/投票检测参数化几何模型（如直线、圆、椭圆或任意模板）的算法。通常以边缘检测的二值边缘图为输入，通过在参数空间寻找峰值来确定最优模型参数。

要点：
- 输入：点集（通常为边缘像素）
- 输出：参数空间中的模型参数（例如直线的 (ρ,θ)，圆的 (a,b,r)）
- 核心思想：参数化 + 累加投票（accumulator）+ 峰值检测


### 参数空间表示

1. 直线（ρ–θ 表示）

- 一般直线方程：\(y=mx+c\)（不适合竖线），常用极坐标参数化：\(\rho = x\cos\theta + y\sin\theta\)。
- 对每个图像点 \((x,y)\)，在参数空间绘制对应的曲线（\(\theta\) 变化时 \(\rho\) 的值），累加交点处为候选直线参数。

2. 圆（中心和半径）

- 圆参数：\((a,b,r)\)，三维参数空间。对于已知半径的情况，可以在二维参数空间（a,b）中投票；若半径未知则需三维累加器或多次投票/约束。

3. 广义霍夫变换（GHT）

- 用于任意形状检测：模板点集合在参数空间（位移、旋转、尺度等）进行投票；通常预计算边缘-方向到模型参考点的映射（R-table）。

### 算法流程（标准 Hough）

1. 预处理：灰度 → 去噪 → 边缘检测（例如 Canny）→ 得到边缘点集合。
2. 参数化：根据模型选择参数化方式（直线 ρ–θ，圆 a,b,r 等）。
3. 累加投票：对每个边缘点，在参数空间按可能参数离散化投票（增加累加器）。
4. 峰值检测：在累加器中寻找局部最大（峰值）作为候选模型。
5. 精化与验证：对每个候选参数在图像空间计算支持度、置信度并可对参数做最小二乘精修或并行剔除重复模型。

注意：累加器离散化（栅格尺寸）、阈值、峰值抑制（non-maximum suppression）/合并策略直接影响检测结果。

### 算法优化与变体

- **梯度约束（Gradient-constrained Hough）**：使用边缘点的梯度方向限制参数空间的投票范围。例如对于直线，边缘法向与直线方向相关，利用梯度可以在 θ 上只在 ±Δθ 范围内投票，极大减少投票量并抑制虚假峰值。

- **概率霍夫变换（Probabilistic Hough Transform, PHT）**：随机采样边缘点进行投票，适用于长直线检测，能大幅降低计算量并返回线段端点信息。OpenCV 提供 `HoughLinesP` 实现。

- **累加器平滑与多尺度**：对累加器做高斯平滑减少量化噪声；使用多尺度/多分辨率处理以同时检测不同尺度的形状。

- **基于边缘强度或权重的加权投票**：将像素的梯度幅值或匹配置信度作为投票权重，提高对强响应点的重视程度。

- **稀疏投票与候选过滤**：先使用局部启发（如霍夫投票局部簇）或粗略投票筛出候选，再对候选做精确投票与拟合。

### 广义霍夫变换（Generalized Hough Transform）

GHT 用于检测任意形状。事先为模型建立 R-table：对模型边缘点记录边缘方向到模型参考点（例如质心）的向量集合；检测时依赖输入边缘点的方向查表并在参数空间投票。GHT 在目标检测与工业模板识别中常用，但对噪声敏感且内存/计算开销大。

### 复杂度与鲁棒性
- 标准霍夫的复杂度受参数维度与累加器分辨率影响：对于三维参数空间（圆的 (a,b,r)）成本较高。
- 在参数空间的分辨率/量化和边缘点数量之间存在折中：分辨率越高定位精度越好，但计算和内存开销增加且峰值更稀疏。
- 霍夫对断裂边缘和部分遮挡较鲁棒（因为投票是累积证据）；但对高密噪点、量化误差和梯度方向错误敏感。

